[{"path":[]},{"path":"https://thieled.github.io/dictvectoR/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://thieled.github.io/dictvectoR/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://thieled.github.io/dictvectoR/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://thieled.github.io/dictvectoR/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://thieled.github.io/dictvectoR/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement [INSERT CONTACT METHOD]. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://thieled.github.io/dictvectoR/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://thieled.github.io/dictvectoR/CODE_OF_CONDUCT.html","id":"1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://thieled.github.io/dictvectoR/CODE_OF_CONDUCT.html","id":"2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://thieled.github.io/dictvectoR/CODE_OF_CONDUCT.html","id":"3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://thieled.github.io/dictvectoR/CODE_OF_CONDUCT.html","id":"4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://thieled.github.io/dictvectoR/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.0, available https://www.contributor-covenant.org/version/2/0/ code_of_conduct.html. Community Impact Guidelines inspired Mozilla’s code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https:// www.contributor-covenant.org/translations.","code":""},{"path":"https://thieled.github.io/dictvectoR/articles/from_text_to_measurement.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"from_text_to_measurement","text":"vignette guides workflow described Thiele (2022) applying ‘Distributed Dictionary Representation’ (DDR) Method (Garten et al., 2018) introduces functions dictvectoR package. DDR method provides continuous measurement concept dataset documents. measurement obtained calculating average word vector representation concept dictionary, representations document, calculating cosine similarity two vectors. detailed description, see Garten et al. (2018) Thiele (2022).","code":""},{"path":"https://thieled.github.io/dictvectoR/articles/from_text_to_measurement.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"from_text_to_measurement","text":"workflow described starts scratch, using textual data input, guides steps finding inductively list keywords, demonstrates evaluation application. requires population dataset containing textual data hand-coded sample drawn dataset, annotated presence theoretical concept. use built-dataset tw_data population data tw_annot annotated sample. vignette follows steps: Pre-process data Train fastText model Finding keywords Add multi-words Get F1 scores Drop similar terms Narrowing hand Get combinations terms. Evaluate performance combinations. Apply best performing dictionary. Face validity.","code":""},{"path":"https://thieled.github.io/dictvectoR/articles/from_text_to_measurement.html","id":"pre-process-data","dir":"Articles","previous_headings":"","what":"Pre-process data","title":"from_text_to_measurement","text":"First load pre-process built textual data. clean_text cleans text tailored German-speaking texts social media. using text languages, may want adapt helper-function needs. prepare_train_data prepares textual data training fastText model. tokenizes longer documents sentences, shuffles , calls clean_text fixed settings. first prepare texts character vector training fastText model, clean text tw_data tw_annot later analyses.","code":"# Prepare text data texts <- prepare_train_data(tw_data, text_field = \"full_text\", seed = 42)  # Clean text in tw_data tw_data %<>% clean_text(remove_stopwords = T,                         text_field = \"full_text\")  # Clean text in tw_annot tw_annot %<>% clean_text(remove_stopwords = T,                          text_field = \"full_text\")"},{"path":"https://thieled.github.io/dictvectoR/articles/from_text_to_measurement.html","id":"train-fasttext-model","dir":"Articles","previous_headings":"","what":"Train fastText model","title":"from_text_to_measurement","text":"Now, train fastText model using fastrtext::build_vectors. customized word vector model advantage maps words contexts actually appear studied material. important , use vocabulary model starting point conceptual dictionary. downside training model expensive regarding memory computation. used machine CPU @ 1.80GHz processor 8 cores 16 GB RAM. run memory limitations, consider decreasing dim, number dimensions. Decreasing number epochs speed learing process, decreasing bucket size reduce size resulting model. details, see Bojanowski et al. (2017). obtain model better quality, also consider increasing size textual data used training. example limited size data can feasibly shipped R-package. Alternatively, may consider using pre-trained model . code creates local folder ft_model user home directory, saves model two files: ft_model.bin ft_model.vec. (Note: code runs model file exists. training algorithm create perfectly identical word vector models, can cause problems re-running vignette.) Let’s load model use nearest-neighbor query check works properly. ‘Spahn’ name former German minister health:","code":"# Create local folder and set name for model dir.create(\"~/ft_model\", showWarnings = FALSE) model_file <- path.expand(\"~/ft_model/ft_model\")  # Train a fasttext model using the twitter data (if model does not yet exist)  if (!file.exists(paste0(model_file, \".bin\"))) {    fastrtext::build_vectors(texts, model_file, modeltype = c(\"skipgram\"),                               dim = 150, epoch = 10, bucket = 1e+6,  lr = 0.05,                               lrUpdateRate = 100, maxn = 7,  minn = 4, minCount = 3,                               t = 1e-04, thread = 8, ws= 6)   } # Load model: model_path <- path.expand(\"~/ft_model/ft_model.bin\") model <- fastrtext::load_model(paste0(model_path))  # Nearest-neigbor query: fastrtext::get_nn(model, \"spahn\", k=8) #>           spahns    spahnversagen             jens  spahnruecktritt  #>        0.9217194        0.7766814        0.7709644        0.7349517  #>    maskenskandal     maskenaffäre personalnotstand          tönnies  #>        0.7219898        0.6807356        0.6642620        0.6540389"},{"path":"https://thieled.github.io/dictvectoR/articles/from_text_to_measurement.html","id":"finding-keywords","dir":"Articles","previous_headings":"","what":"Finding keywords","title":"from_text_to_measurement","text":"Next, want use fastText model manually annotated dataset find short dictionary populist communication. First, split annotated data train test sample, using caret::createDataPartition. starting point dictionary, use vocabulary fastText model. add ID vocabulary use clean_text remove stopwords, drop words less 3 characters list: Next, want narrow list. identify words similar hand-coded corpus populist Tweets dissimilar non-populist Tweets df_train using find_distinctive. find_distinctive computes average representation subset annotated corpus populism coded present, well representation negative counterpart, .e. non-populist corpus. computes cosine similarities word dataframe two corpora, calculates difference two similarity scores. provides us quick computationally inexpensive shortcut find keywords capture specific concept, nothing else. However, method narrowing list keywords bit crude informative assessing well single word perform used DDR method. Hence, want get actual F1 scores single word, used one-word-dicitonary DDR method. Note DDR method returns cosine similarity continuous measure, theoretically ranging -1 +1, manually annotated dataset coded binary fashion (populist non-populist). solve problem, continuous measure used independent variable logistic regression, predicting manual binary coding. obtain Recall, Precision F1 scores, dictvectoR compares binary predictions resulting regression manual coding. direct gold standard test circumvents problem producing reliable granular codes manually (Grimmer & Stewart, 2013, p. 275). Recall evaluation metric indicates well automated measure captures true positives, precision indicates well captures true positives, F1 harmonic mean (Chinchor 1992). get_many_F1s function efficiently returns F1 scores list words dictionaries, used dictionary DDR method. ’re interested best-performing quartile, extract using helper-function filter_ntile:","code":"# set seed set.seed(42)  # get index for splitting train_id <- caret::createDataPartition(tw_annot$pop,                                 times = 1,                                 p = .7,                                 list = F) # split annotated data df_train <- tw_annot %>% slice(train_id)  df_test <- tw_annot %>% slice(-train_id) # # Get vocabulary vocab_df <- fastrtext::get_dictionary(model) %>% data.frame(words = .)  # Get vocabulary ID vocab_df$word_id <- fastrtext::get_word_ids(model, vocab_df$words)  # remove stopwords vocab_df <- clean_text(vocab_df,                         text_field = \"words\",                        remove_stopwords = T) %>%             filter(n_words == 1,                    n_chars > 2) # Get distinctive word scores vocab_df <- find_distinctive(df_train,                               concept_field = \"pop\",                              text_field = \"text\",                              word_df = vocab_df,                              word_field = \"words\",                              model = model)  vocab_df %<>% mutate(pop_distinctiveXpossim = pop_distinctive*pop_possim) %>%                filter_ntile(\"pop_distinctiveXpossim\", .75) vocab_df$popF1 <- get_many_F1s(vocab_df$words,                               model = model,                               df = df_train,                               reference = \"pop\") top <- vocab_df %>%               filter_ntile(\"popF1\", .75) %>%              filter(popF1 > 0)"},{"path":"https://thieled.github.io/dictvectoR/articles/from_text_to_measurement.html","id":"add-multi-words","dir":"Articles","previous_headings":"","what":"Add multi-words","title":"from_text_to_measurement","text":"concepts expressed rather multi-word expressions single words. case, suspect people-centrism, one core dimension populism, may involve multiword expressions, example constructing -group references ‘’, e.g., ‘taxpayers’, ‘land’ etc. find common multiword expressions, use population data (75 percent speed process bit), tokenize using quanteda::tokens. add_multiwords adds multiword expressions dataframe single words counts occurences. look multiwords 2-word-window (level = 1), can increased 3-words window (level = 2). process might take two three minutes. want narrow list , filtering terms occur . add unique word_id add_word_id.","code":"tw_data %<>% filter(n_words >= 2)  # Use 75% sample set.seed(42) tw_split <- tw_data %>% slice_sample(prop = .75)  # tokenize toks <- quanteda::tokens(tw_split$text) top <- add_multiwords(top,                        tokens = toks,                        min_hits = 1,                       word_field = \"words\",                       levels = 1) #> [1] \"Finding multi-word expressions in window = 1...\" #> Joining, by = \"from\" #> [1] \"Adding missing count of original words:\" #> [1] \"Counting word occurrences...\" top %<>% filter(hits > 1)  top %<>% add_word_id()"},{"path":"https://thieled.github.io/dictvectoR/articles/from_text_to_measurement.html","id":"get-f1-scores","dir":"Articles","previous_headings":"","what":"Get F1 scores","title":"from_text_to_measurement","text":"Now, also want know F1 scores new multiword terms, hence just run get_many_F1s .","code":"top$popF1 <- get_many_F1s(top$words,                           model = model,                           df = df_train,                           reference = \"pop\")"},{"path":"https://thieled.github.io/dictvectoR/articles/from_text_to_measurement.html","id":"drop-similar-terms","dir":"Articles","previous_headings":"","what":"Drop similar terms","title":"from_text_to_measurement","text":"resulting list words quite long includes lot redundancy. Note unlike traditional dictionary approaches, DDR method performs better input dictionary short clear-cut. redundancy problem traditional dictionaries, may distort performance dictionary DDR (Garten et al., 2018). remove_similar_words helps us detect similar terms - computing pairwise cosine similarity words representations datafram. can use two score input decide words drop: use F1 score calculated popF1, number occurences (compare_hits = T). set function compare terms reach smiliarity 60% (min_simil = .6). win_threshold defines share comparisons term must win order remain dataframe. Additionally, drop terms originate uni-word afd, German populist party, since want populism measure rather non-partisan:","code":"## narrow down top_subs <- top %>% remove_similar_words(model,                                          compare_by = \"popF1\",                                         compare_hits = T,                                          min_simil = .6,                                          win_threshold = .65) %>%                      filter(!from == \"afd\")  #> Warning in .recacheSubclasses(def@className, def, env): undefined subclass #> \"unpackedMatrix\" of class \"mMatrix\"; definition not updated #> Warning in .recacheSubclasses(def@className, def, env): undefined subclass #> \"unpackedMatrix\" of class \"replValueSp\"; definition not updated"},{"path":"https://thieled.github.io/dictvectoR/articles/from_text_to_measurement.html","id":"narrowing-down-by-hand","dir":"Articles","previous_headings":"","what":"Narrowing down by hand","title":"from_text_to_measurement","text":"Let’s look terms found far. (won’t print 400 terms top 50) list keywors still quite long. includes many terms seem theoretically plausible, also many words obviously either specific, seem place. Since next steps involve combinatorics finding good combination keywords, want narrow list words drastically possible. theoretical reasons, decided group found words three categories reflect different aspects populist communication: Terms reflect ‘elites’, terms reflect ‘people’, words relate two groups. 400 terms, hand-picked five distinctive terms categories. mode selection theory-driven different inductive logic used far. may want opt different modes selection, depending task quality inductively generated keywords. words picked processing: use hand-picked list words create shortlist add variable indicates category:","code":"top_subs %>% arrange(desc(popF1)) %>% pull(words) %>% head(50) #>  [1] \"panzer\"                  \"wahn\"                    #>  [3] \"deutschen steuerzahler\"  \"verrechnet\"              #>  [5] \"wand\"                    \"steuergeldverschwendung\" #>  [7] \"rücken wand\"             \"banken\"                  #>  [9] \"teures\"                  \"gaga\"                    #> [11] \"verrückt\"                \"gender gaga\"             #> [13] \"irrsinnige\"              \"vernichtet\"              #> [15] \"steuerzahler\"            \"mdb groko\"               #> [17] \"skandalösen\"             \"mdb nimmt\"               #> [19] \"igmetall\"                \"existenzen vernichtet\"   #> [21] \"maskenskandal\"           \"deckt\"                   #> [23] \"deutschen mittelstand\"   \"betreibt\"                #> [25] \"autofahrer\"              \"deutschland groko\"       #> [27] \"skandalöse\"              \"daimler vw\"              #> [29] \"schamlos\"                \"sondervermögen\"          #> [31] \"spahn warnt\"             \"lobbyregister\"           #> [33] \"gendergaga\"              \"vdk\"                     #> [35] \"vernichten\"              \"dax\"                     #> [37] \"staatshaushalt\"          \"deutsche steuerzahler\"   #> [39] \"merkels groko\"           \"finanzministerium\"       #> [41] \"knickt\"                  \"suizid\"                  #> [43] \"irrweg\"                  \"maut desaster\"           #> [45] \"gender\"                  \"steuergeldern\"           #> [47] \"skandalös\"               \"deckmantel\"              #> [49] \"entlarven\"               \"ganzer linie\" elites <- c( \"altparteien\",  \"lobbyisten\",  \"merkel co\",  \"plänen bundesregierung\",  \"zwangsgebühr\"  )  people <- c( \"arbeitnehmern\",   \"existenzen\",  \"deutschen\",  \"deutschen mittelstand\",  \"deutschen steuerzahler\"  )  relation <- c( \"entlarven\",  \"schamlos\",  \"verrückt\", \"wahn\",  \"steuergeldverschwendung\"  ) top_elites <- top_subs %>% filter(words %in% elites) %>% mutate(cat = \"elites\") top_people <- top_subs %>% filter(words %in% people) %>% mutate(cat = \"people\") top_relation <- top_subs %>% filter(words %in% relation) %>% mutate(cat = \"relation\")  shortlist <- bind_rows(top_elites, top_people, top_relation)  shortlist$cat %<>% factor()  shortlist$cat %>% summary() #>   elites   people relation  #>        5        4        5"},{"path":"https://thieled.github.io/dictvectoR/articles/from_text_to_measurement.html","id":"get-combinations","dir":"Articles","previous_headings":"","what":"Get combinations","title":"from_text_to_measurement","text":"now use shortlist get possible combinations various length per category, possible combinations combinations. get_combis helps us finding combinations, provides useful random sampling mechanism limits number returned combinations: Setting limit, limits number combinations given length returned per dimension. example, consider shortlist words 2 categories B, 10 words per category, want find combinations words include least 3 words per category (min_per_dim = 3) maximum 10 words overall (max_overall = 10), .e. max. 5 words per dimension. 120 possible combinations length 3 category B: However, also get 210 possible combinations length 4, 252 combinations length 5 per category: want get possible combinations combinations, number increases really quickly, can see . first two lines return possible cominations B varying length 3 5. expand_grid returns combinations combinations: Setting limit , let’s say 30, get_combis radomly draws 30 possible combinations one length per category. case, limit really necessary, 5 words per category want lengths 3 4. maximum number combinations per length & category 10: Although unnecessary case, specify limit (won’t drop combinations) - just demonstration. Setting seed makes results reproducible, default 1. get_cobmis returns data.frame includes column ’re settings stored, case want come back draw different round combinations. , let’s get combinations list words:","code":"A <- c(1:10) B <- c(11:20)  choose(10, 3) #> [1] 120 choose(10, 4) #> [1] 210 choose(10, 5) #> [1] 252 A_c <- do.call(\"c\", lapply(3:5, function(i) combn(A, i, FUN = list))) B_c <- do.call(\"c\", lapply(3:5, function(i) combn(B, i, FUN = list))) expand.grid(A_c, B_c)  %>% nrow() #> [1] 338724 max(   choose(5, 3),   choose(5, 4) ) #> [1] 10 combis_rd <- get_combis(shortlist,                         dims = \"cat\",                         min_per_dim = 3,                         max_overall = 12,                         limit = 10,                         seed = 42) #> Joining, by = \"rowid\""},{"path":"https://thieled.github.io/dictvectoR/articles/from_text_to_measurement.html","id":"evaluate-combinations","dir":"Articles","previous_headings":"","what":"Evaluate combinations","title":"from_text_to_measurement","text":"Now want get Recall, Precision, F1 scores 3,375 combinations. get_many_RPFs made task: Now, let’s pick best performing short dictionary: 10 words cover various aspects populist communication highly context-specific. However, place dive theoretical discussions. Let’s check performance dictionary instead. training sample, dictionary reaches F1 .56, great, OK. Let’s check F1 score applied test sample: short dictionary reaches F1 .55 test sample, almost par result train data. Drawing evaluation, reason assume avoided overfitting dictionary training data. may therefore assume measurement can least approximately capture populist communication population dataset. mean short dictionary perform equally well different contexts, e.g., user-generated material, timeframes. special applications, might intereste DDR measurement perform different subsets data, e.g., using translated corpus originating various languages. F1 scores grouped subsets text dataframe, can obtained get_many_F1s_by_group. case, might interested dictionaries perform different political parties. , demonstrate function using top 5% short dictionaries. Since populist communication annotated sample indeed mainly concentrated parties AfD Die Linke, calculate 3rd root product overall F1 score two party-specific F1-scores pick best performing, balanced dictionary: Let’s check performance ‘balanced’ dictionary test data: decreased performance test data, stick dictionary picked .","code":"combis_df <- get_many_RPFs(keyword_df = combis_rd,                              keyword_field = \"combs_split\",                              model = model,                               text_df = df_train,                              reference = \"pop\",                               text_field = \"text\") #> Joining, by = \"rowid\" # Pick dictionary that maximizes F1: dict  <- combis_df %>%            filter(F1 == max(F1)) %>%            pull(combs_split) %>%           unlist()  # Let's see: dict #>  [1] \"deutschen\"              \"deutschen mittelstand\"  \"entlarven\"              #>  [4] \"existenzen\"             \"lobbyisten\"             \"merkel co\"              #>  [7] \"plänen bundesregierung\" \"schamlos\"               \"verrückt\"               #> [10] \"zwangsgebühr\" combis_df$F1 %>% max()   #> [1] 0.5625 # Performance for test_df get_F1(df_test, dict, model, 'pop') #> [1] 0.4897959 combis_subset <- combis_df %>% filter_ntile(\"F1\", .95)  combis_df_by_group <-  get_many_F1s_by_group(keyword_df = combis_subset,                                              keyword_field = \"combs_split\",                                              id = \"id\",                                              model = model,                                              text_df = df_train,                                              group_field = \"party\",                                              reference = 'pop') #> Joining, by = \"id\" # Compute 3rd root product of 3 F1s: combis_df_by_group %<>% mutate(F1_balanced = (F1*F1_AfD*F1_Linke)^(1/3))  dict_bal  <- combis_df_by_group %>%                          filter(F1_balanced == max(F1_balanced)) %>%                          pull(combs_split) %>%                         unlist()  dict_bal #> [1] \"altparteien\"             \"deutschen mittelstand\"   #> [3] \"deutschen steuerzahler\"  \"existenzen\"              #> [5] \"lobbyisten\"              \"plänen bundesregierung\"  #> [7] \"steuergeldverschwendung\" \"verrückt\"                #> [9] \"wahn\" get_F1(df_test, dict_bal, model, 'pop') #> [1] 0.5"},{"path":"https://thieled.github.io/dictvectoR/articles/from_text_to_measurement.html","id":"apply-ddr","dir":"Articles","previous_headings":"","what":"Apply DDR","title":"from_text_to_measurement","text":"Now, want apply best performing dictionary datasets. apply , population data tw_data annotated data tw_annot, using core function package cossim2dict. fill missing values, occure sometimes text cleaning empties text field mean minus 1 SD:","code":"tw_annot$pop_ddr <- cossim2dict(df = tw_annot,                                dictionary = dict,                                model = model,                                replace_na = 'mean-sd')  tw_data$pop_ddr <- cossim2dict(df = tw_data,                                dictionary = dict,                                model = model,                                replace_na = 'mean-sd')"},{"path":"https://thieled.github.io/dictvectoR/articles/from_text_to_measurement.html","id":"face-validity","dir":"Articles","previous_headings":"","what":"Face validity","title":"from_text_to_measurement","text":"Now, lets inspect top 3 populist Tweets population data: examples include Tweets AfD directed ‘genderism’ leftist ideology, directed EU, directed climate politics. Judging face validity Tweets clearly populist. Let’s inspect lower end spectrum: least populist Tweets - according measurement - include quite harmless “get well soon” wishes.","code":"tw_data %>% arrange(desc(pop_ddr)) %>% pull(full_text) %>% head(3) #> [1] \"#AfD-Fraktionsvize @PeterFelser hat den linksideologischen Hype um neue Geschlechter als „teures #Gendergaga“ kritisiert: \\\"Riesen Aufwand für Nichts! Gender-Gaga auf Kosten der #Steuerzahler ersatzlos streichen!\\\" #Bundestag https://t.co/paIVvtTkfg\"                                      #> [2] \"Seit es das #Grundgesetz gibt, hatte #Deutschland keinen Regierungschef, der deutsche Interessen so schlecht vertritt und den Ausverkauf des deutschen Volksvermögens und der Staatsfinanzen so schamlos betreibt, wie Angela #Merkel! #AfD #Corona #Covid19 https://t.co/qGKYUgqcSe\"           #> [3] \"Entwicklungsminister Gerd Müller &amp; Arbeitsminister @hubertus_heil wollen ein Lieferkettengesetz durchsetzen, das eine nahezu unbegrenzte Haftungsausweitung für 🇩🇪 Unternehmen vorsieht. @Frohnmaier_AfD: \\\"Schlussstrich unter Lieferketten-Irrsinn ziehen\\\" #AfD https://t.co/mW9wvDrFaI\" tw_data %>% arrange(desc(pop_ddr)) %>% pull(full_text) %>% tail(3) #> [1] \"@ralphruthe @marga_owski Gute Besserung!\"                       #> [2] \"@BelaAnda1 @walli5 @PolyPepper Ohne Diblom glaub‘ ich des ned.\" #> [3] \"@grischdjane @doktordab @MarkusBlume So ein Käse Käse ;-)\""},{"path":"https://thieled.github.io/dictvectoR/articles/from_text_to_measurement.html","id":"plots","dir":"Articles","previous_headings":"","what":"Plots","title":"from_text_to_measurement","text":"Let’s use DDR measurements plots. start plotting gradual populism measurement human, binary coding populism, using complete annotated dataset:  see non-populist Tweets score higher , mean populism score groups clearly different - indicated boxplots. can also use parallel-coded 90 Tweets get visual evaluation gradual measurement returned DDR method. ‘Populism’ annotated dataset coded two distinct categories, anti-elitism people-centrism. obtain gradual score, just calculate sum coding two categories two coders, resulting score ranges 0 4. plot DDR score:  two (semi-)continuous scores Pearson’s r correlation .53: Finally, assess external validity measurement, compare aggregated level POPPA expert rating political parties (Meijers Zaslove, 2020). expert survey provides gradual rating populism political parties. score already merged tw_data.  aggregate level, expert ratings populism political parties align well DDR score populist communication. Indeed, scores strongly correlated:","code":"tw_annot$pop %<>% factor()   ggplot(tw_annot, aes(x = pop, y = pop_ddr, color = pop)) +    geom_boxplot()+   geom_jitter(width = .2)+   theme_bw()+   labs(y = \"Populism (DDR)\",         x = \"Populism (Human coding)\")+   theme(axis.title.x = element_text(hjust = 0),         legend.position=\"none\") parallel_df <- tw_annot %>%   filter(rel_test == 1) %>%   mutate(pop_cum = ppc_A + ppc_B + ane_A + ane_B)   ggplot(parallel_df, aes(x = pop_ddr, y = pop_cum))+   geom_jitter(height = .1,               width = 0)+   geom_smooth(method = lm, se = T)+   coord_cartesian(ylim = c(0,4)) cor(parallel_df$pop_cum, parallel_df$pop_ddr) #> [1] 0.5308004 # aggregate on party level tw_party <- tw_data %>%                group_by(party) %>%               summarise(pop_ddr = mean(pop_ddr),                         poppa_populism = mean(poppa_populism))    ggplot(tw_party, aes(x = pop_ddr, y = poppa_populism, label=party))+   geom_point(na.rm = T)+   geom_smooth(method = lm)+   geom_text(hjust=0, vjust=0) cor(tw_party$pop_ddr, tw_party$poppa_populism) #> [1] 0.87111"},{"path":"https://thieled.github.io/dictvectoR/articles/from_text_to_measurement.html","id":"simple-visual-analysis","dir":"Articles","previous_headings":"","what":"Simple visual analysis","title":"from_text_to_measurement","text":"resulting DDR scores used, e.g. investigate temporal shifts strategies political parties. plot mean populism score per party time. see ‘AfD’ clearly populist party, followed ‘Die Linke’, theoretically absolutely plausible. sudden decrease populist communication ‘Die Linke’ parties August 2020, driven growth populist coronasceptic movement - opposed parties ‘AfD’. end timeframe, shortly German General Elections September 2021, level populism rises notably ‘AfD’.","code":"tw_data %>%     mutate(day = as.Date(created_at)) %>%      group_by(party, day) %>%      summarise(pop_ddr = mean(pop_ddr)) %>%      ggplot(aes(x = day, y = pop_ddr, color = party))+     geom_smooth(method = 'loess', span = 0.15, se = F)"},{"path":"https://thieled.github.io/dictvectoR/articles/from_text_to_measurement.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"from_text_to_measurement","text":"Summing , dictionary measurement produced vignette good job differentiating levels populism communication political parties, aggregate level. also produces somehow plausible results compared cumulative coding two coders. performs OK compared directly binary hand-codings Tweets. However, much room improvement. possible ways improve measurement: Improve fastText model using much larger training dataset. Pre-trained models trained millions sentences, example. However, unlike generic models, may want stick material specific context (: communication political elites). Improve fastText model parameter tuning. E.g., donsider increasing number dimensions (dim, 100-300 popular choices), increasing number epochs (epoch), play around different ngram lengths (minn, maxn), play around window size context (ws). can use get_nn face validity plausibility checks, use formal test (e.g., analogy tests) determine quality fastText model. Use larger annotated sample finding good keywords evaluating quality. larger sample, lower risk overfitting short dictionary specific context. Play around different thresholds remove_similar_terms. function can quite dramatic effect words included excluded. Think theory-driven, explicit coding-scheme hand-picking words narrowed subset. Allow combinations per length dimension (limit) get_combis. Good luck!","code":""},{"path":"https://thieled.github.io/dictvectoR/articles/from_text_to_measurement.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"from_text_to_measurement","text":"Bojanowski, P., Grave, E., Joulin, ., & Mikolov, T. (2017). Enriching Word Vectors Subword Information. ArXiv:1607.04606 [Cs]. Retrieved http://arxiv.org/abs/1607.04606 Chinchor, N. (1992). MUC-4 evaluation metrics. Proceedings 4th Conference Message Understanding, 22–29. USA: Association Computational Linguistics. https://doi.org/10.3115/1072064.1072067 Garten, J., Hoover, J., Johnson, K. M., Boghrati, R., Iskiwitch, C., & Dehghani, M. (2018). Dictionaries distributions: Combining expert knowledge large scale textual data content analysis. Behavior Research Methods, 50(1), 344–361. https://doi.org/10.3758/s13428-017-0875-9 Grimmer, J., & Stewart, B. M. (2013). Text data: promise pitfalls automatic content analysis methods political texts. Political Analysis, 21(3), 267–297. https://doi.org/10.1093/pan/mps028 Meijers, M., & Zaslove, . (2020). Populism Political Parties Expert Survey 2018 (POPPA) (Data set). Harvard Dataverse. https://doi.org/10.7910/DVN/8NEL7B Thiele, D. (2022, June 27). “Don’t believe media’s pandemic propaganda!!” Covid-19 affected populist Facebook user comments seven European countries. Presented ICA Regional Conference 2022. Computational Communication Research Central Eastern Europe, Helsinki, Finland. Retrieved https://ucloud.univie.ac./index.php/s/PzGzChXroLCXrtt","code":""},{"path":"https://thieled.github.io/dictvectoR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Daniel Thiele. Maintainer, author.","code":""},{"path":"https://thieled.github.io/dictvectoR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Thiele D (2022). dictvectoR:  Word vectors dictionaries . https://github.com/thieled, https://thieled.github.io/dictvectoR/.","code":"@Manual{,   title = {dictvectoR: {{ Word vectors for dictionaries }}},   author = {Daniel Thiele},   year = {2022},   note = {https://github.com/thieled, https://thieled.github.io/dictvectoR/}, }"},{"path":"https://thieled.github.io/dictvectoR/index.html","id":"dictvector-","dir":"","previous_headings":"","what":"{{ Word vectors for dictionaries }}","title":"{{ Word vectors for dictionaries }}","text":"dictvectoR implements “Distributed Dictionary Representation” (DDR) Method (Garten et al., 2018). DDR uses word vector representation dictionary, .e. list words reflect theoretical concept, calculate “continuous measure similarity concept piece text” [1]. Word vectors, also called word embeddings, aim represent semantic proximity words vector space [2]. package uses fastText word vectors [3]. Average vector representations computed concept dictionary document. DDR score cosine similarity vectors [1]. addition core function, package comes range functions help find keywords assess performance words dictionaries. can learn workflow training fastText model, finding good dictionary, evaluating performance vignette(\"from_text_to_measurement\"). workflow described greater detail [4]. demonstrate usage, package comes corpus 20,838 Tweets 32 Twitter accounts German politics, published 2020-03-11 2021-09-25, hand-coded sample 1,000 Tweets corpus, coded along two binary variables populist communication: Anti-elitism people-centrism. package also includes minimal fastText model, serves provide working examples functions package recommended used actual analysis.","code":""},{"path":"https://thieled.github.io/dictvectoR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"{{ Word vectors for dictionaries }}","text":"can install development version dictvectoR GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"thieled/dictvectoR\")"},{"path":"https://thieled.github.io/dictvectoR/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"{{ Word vectors for dictionaries }}","text":"basic example, starting scratch, using built-Twitter data German politicians Covid-crisis. get started, need fastText word vector model, train pre-processed data, cleaned, split, shuffled [prepare_train_data]. demonstration purposes, keep model simple small. actual application, might want consider using much textual data, epochs, dimensions larger bucket size. might also consider using (task-specific) pre-trained model . (Note: code create fastText model user home directory deleted end readme.) text data loaded Tweets German politicians, posted beginning Covid pandemic German General Elections September 2021. First, clean textual data, using helper function [clean_text], tailored German social media texts. Now, lets apply DDR method. Let’s say want measure degree populism Tweets. first define ad-hoc short dictionary consider reflect important dimensions populist communication apply DDR method using short dictionary [cossim2dict]. Let’s look top 3 populist Tweets, according ad-hoc measurement: speak German, can judge face-validity top results appear quite plausible. Let’s quick look measurement can re-create scores POPPA expert survey, rated parties along contiuous score populism. score already included tw_data:  aggregate level, expert survey rating ad-hoc DDR measurement highly correlated:","code":"library(dictvectoR) library(dplyr)  # Prepare text data. Cleans, splits, and shuffles textual data texts <- prepare_train_data(tw_data, text_field = \"full_text\", seed = 42)  # Create local folder, set model file name dir.create(\"~/ft_model_readme\", showWarnings = FALSE) model_file <- path.expand(\"~/ft_model_readme/ft_model_demo\")  # Train a fasttext model using the twitter data fastrtext::build_vectors(texts,                           model_file,                           modeltype = c(\"skipgram\"),                          dim = 70, epoch = 5, bucket = 5e+4, lr = 0.1,                          maxn = 6,  minn = 4, minCount = 4,                          verbose = 1, ws= 5)  # Load model: model_path <- path.expand(\"~/ft_model_readme/ft_model_demo.bin\") model <- fastrtext::load_model(paste0(model_path)) tw_data %<>% clean_text(text_field = \"full_text\", remove_stopwords = T) # Define a short dictionary pop_dict <- c(\"merkel\",               \"irrsinn\",               \"diktatur\",               \"lobbyismus\",               \"arbeitende menschen\",               \"deutschland\",               \"unsere steuergelder\")  # Get the DDR score tw_data$pop_ddr <- cossim2dict(tw_data, pop_dict, model, replace_na = 'mean-sd') tw_data %>%   dplyr::arrange(desc(pop_ddr)) %>%   head(3) %>%   dplyr::pull(full_text) #> [1] \"Ob Deutschkurs oder Job - die Bilanz von \\\"geflüchteten\\\" #Frauen stellt sich nach fünf Jahren in #Deutschland ernüchternd dar. Merkels Fachkräfte-Märchen zerschellt krachend an der Realität - - der deutsche #Sozialstaat machts möglich! #AfD #Migration https://t.co/oTrP2ewkpv https://t.co/kr4PPh2a1z\" #> [2] \"#UNO finanziert #Islamisten-#Hass mit unserem #Steuergeld!\\n\\nSeit Jahrzehnten haben die Vereinten Nationen ein massives Problem mit #Islamismus und islamischem #Antisemitismus in den eigenen Reihen – und es wird nicht besser.\\n\\nhttps://t.co/G9MMaQrqIY https://t.co/fzjQ8Ty2qq\"                        #> [3] \"Seit es das #Grundgesetz gibt, hatte #Deutschland keinen Regierungschef, der deutsche Interessen so schlecht vertritt und den Ausverkauf des deutschen Volksvermögens und der Staatsfinanzen so schamlos betreibt, wie Angela #Merkel! #AfD #Corona #Covid19 https://t.co/qGKYUgqcSe\" # aggregate tw_party <- tw_data %>%                group_by(party) %>%               summarise(pop_ddr = mean(pop_ddr),                         poppa_populism = mean(poppa_populism))   # plot library(ggplot2) ggplot(tw_party, aes(x = pop_ddr, y = poppa_populism, label=party))+   geom_point(na.rm = T)+   geom_smooth(method = lm)+   geom_text(hjust=0, vjust=0) cor(tw_party$pop_ddr, tw_party$poppa_populism) #> [1] 0.8342808"},{"path":"https://thieled.github.io/dictvectoR/index.html","id":"finding-keywords","dir":"","previous_headings":"","what":"Finding keywords","title":"{{ Word vectors for dictionaries }}","text":"dictvectoR provides variety functions inductively find good keywords efficiently assess performance many . can learn complete workflow vignette(\"from_text_to_measurement\"). fun! (first, let’s delete demo model:)","code":"unlink(\"~/ft_model_readme\", recursive = TRUE)"},{"path":"https://thieled.github.io/dictvectoR/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"{{ Word vectors for dictionaries }}","text":"[1] Garten, J., Hoover, J., Johnson, K. M., Boghrati, R., Iskiwitch, C., & Dehghani, M. (2018). Dictionaries distributions: Combining expert knowledge large scale textual data content analysis. Behavior Research Methods, 50(1), 344–361. https://doi.org/10.3758/s13428-017-0875-9 [2] Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient Estimation Word Representations Vector Space. ArXiv:1301.3781 [Cs]. http://arxiv.org/abs/1301.3781 [3] Bojanowski, P., Grave, E., Joulin, ., & Mikolov, T. (2017). Enriching Word Vectors Subword Information. ArXiv:1607.04606 [Cs]. Retrieved http://arxiv.org/abs/1607.04606 [4] Thiele, D. (2022, June 27). “Don’t believe media’s pandemic propaganda!!” Covid-19 affected populist Facebook user comments seven European countries. Presented ICA Regional Conference 2022. Computational Communication Research Central Eastern Europe, Helsinki, Finland. Retrieved https://ucloud.univie.ac./index.php/s/PzGzChXroLCXrtt [5] Meijers, M., & Zaslove, . (2020). Populism Political Parties Expert Survey 2018 (POPPA) [Data set]. Harvard Dataverse. https://doi.org/10.7910/DVN/8NEL7B","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/add_id.html","id":null,"dir":"Reference","previous_headings":"","what":"Add id — add_id","title":"Add id — add_id","text":"Function add 'id' data.frame already .","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/add_id.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add id — add_id","text":"","code":"add_id(df)"},{"path":"https://thieled.github.io/dictvectoR/reference/add_id.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add id — add_id","text":"df data.frame.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/add_id.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add id — add_id","text":"data.frame includes column called 'id' type 'character' contains unique identifiers rows data.frame.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/add_id.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add id — add_id","text":"Searches data.frame variables include 'id' name. Checks unique identifier. , variable renamed 'word_id' forced type 'character'. , new column named 'word_id' type 'character' created, containing string numbers uniquely identify rows data.frame.","code":""},{"path":[]},{"path":"https://thieled.github.io/dictvectoR/reference/add_id.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add id — add_id","text":"","code":"t1 <- data.frame(id = 1:10, a = sample(letters, 10)) t2 <- data.frame(id = rep(1, 10),                 word_id = sprintf(\"%02d\", 1:10),                 a = sample(letters, 10)) t3 <- data.frame(a = sample(letters, 10)) add_id(t1) #>    id a #> 1   1 r #> 2   2 p #> 3   3 a #> 4   4 u #> 5   5 t #> 6   6 y #> 7   7 k #> 8   8 l #> 9   9 m #> 10 10 q add_id(t2) #>    id a #> 1  01 g #> 2  02 y #> 3  03 l #> 4  04 t #> 5  05 e #> 6  06 u #> 7  07 h #> 8  08 b #> 9  09 d #> 10 10 z add_id(t3) #>    a id #> 1  e 01 #> 2  i 02 #> 3  w 03 #> 4  o 04 #> 5  b 05 #> 6  l 06 #> 7  n 07 #> 8  u 08 #> 9  c 09 #> 10 f 10"},{"path":"https://thieled.github.io/dictvectoR/reference/add_multiwords.html","id":null,"dir":"Reference","previous_headings":"","what":"Find multi-word expressions. — add_multiwords","title":"Find multi-word expressions. — add_multiwords","text":"Adds multi-word expressions found quanteda tokens object data.frame words.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/add_multiwords.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find multi-word expressions. — add_multiwords","text":"","code":"add_multiwords(   word_df,   tokens,   min_hits = 3,   word_field = \"words\",   levels = c(1, 2) )"},{"path":"https://thieled.github.io/dictvectoR/reference/add_multiwords.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find multi-word expressions. — add_multiwords","text":"word_df data.frame containing words. tokens word-tokens object, returned quanteda::tokens. min_hits Numerical. Default 3. Minimum occurrence found multi-word expressions. word_field Character. Default \"words\". Name column word_df contains words. levels Numerical (1 2). window size multi-word expressions.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/add_multiwords.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find multi-word expressions. — add_multiwords","text":"data.frame information word_df, added multi-word expressions rows. Additionally, returned data.frame contains columns... 'orig_id' unique identifier original word, re-used word_df created new present '' indicating word origin 'word_id (character) unique identifier words multi-words 'hits indicating number occurrences word multi-word","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/add_multiwords.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find multi-word expressions. — add_multiwords","text":"","code":"tw_data %<>% head(100) %>% clean_text(text_field = 'full_text') #> Warning: undefined subclass \"unpackedMatrix\" of class \"mMatrix\"; definition not updated #> Warning: undefined subclass \"unpackedMatrix\" of class \"replValueSp\"; definition not updated toks <- quanteda::tokens(tw_data$text) data.frame(words = c(\"deutschen\", \"millionen\")) %>%             add_multiwords(tokens = toks,             min_hits = 1,             levels = 1) #> [1] \"Finding multi-word expressions in window = 1...\" #> Joining, by = \"from\" #> [1] \"Adding missing count of original words:\" #> [1] \"Counting word occurrences...\" #>                               words      from word_id orig_id hits #> 3                     der deutschen deutschen   1_001       1    3 #> 1                         deutschen deutschen       1       1    6 #> 7             deutschen autokonzern deutschen   1_005       1    1 #> 9               deutschen bundestag deutschen   1_007       1    1 #> 11 deutschen kommissionspräsidentin deutschen   1_009       1    1 #> 12                deutschen politik deutschen   1_010       1    1 #> 10            deutschen unternehmen deutschen   1_008       1    1 #> 8              deutschen wirtschaft deutschen   1_006       1    1 #> 6                   einer deutschen deutschen   1_004       1    1 #> 5                      im deutschen deutschen   1_003       1    1 #> 4                  keinen deutschen deutschen   1_002       1    1 #> 2                         millionen millionen       2       2    3 #> 17                   millionen euro millionen   2_005       2    1 #> 16                millionen pendler millionen   2_004       2    1 #> 15                    millionen von millionen   2_003       2    1 #> 13                   sind millionen millionen   2_001       2    1 #> 14                vierzig millionen millionen   2_002       2    1"},{"path":"https://thieled.github.io/dictvectoR/reference/add_word_id.html","id":null,"dir":"Reference","previous_headings":"","what":"Add word_id. — add_word_id","title":"Add word_id. — add_word_id","text":"Function add word_id data.frame already .","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/add_word_id.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add word_id. — add_word_id","text":"","code":"add_word_id(df)"},{"path":"https://thieled.github.io/dictvectoR/reference/add_word_id.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add word_id. — add_word_id","text":"df data.frame.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/add_word_id.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add word_id. — add_word_id","text":"data.frame includes column called 'word_id' type 'character' contains unique identifiers rows data.frame.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/add_word_id.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add word_id. — add_word_id","text":"Searches data.frame variables include 'id' name. Checks unique identifier. , variable renamed 'word_id' forced type 'character'. , new column named 'word_id' type 'character' created, containing string numbers uniquely identify rows data.frame.","code":""},{"path":[]},{"path":"https://thieled.github.io/dictvectoR/reference/add_word_id.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add word_id. — add_word_id","text":"","code":"t1 <- data.frame(wid = 1:10, a = sample(letters, 10)) t2 <- data.frame(id = rep(1, 10),                 word_id = sprintf(\"%02d\", 1:10),                 a = sample(letters, 10)) t3 <- data.frame(a = sample(letters, 10)) add_word_id(t1) #>    a word_id #> 1  d       1 #> 2  o       2 #> 3  z       3 #> 4  b       4 #> 5  k       5 #> 6  l       6 #> 7  i       7 #> 8  v       8 #> 9  m       9 #> 10 c      10 add_word_id(t2) #>    id word_id a #> 1   1      01 y #> 2   1      02 q #> 3   1      03 r #> 4   1      04 n #> 5   1      05 c #> 6   1      06 v #> 7   1      07 s #> 8   1      08 x #> 9   1      09 o #> 10  1      10 j add_word_id(t3) #>    a word_id #> 1  k      01 #> 2  s      02 #> 3  e      03 #> 4  o      04 #> 5  x      05 #> 6  g      06 #> 7  m      07 #> 8  w      08 #> 9  q      09 #> 10 v      10"},{"path":"https://thieled.github.io/dictvectoR/reference/clean_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Clean text — clean_text","title":"Clean text — clean_text","text":"Cleans text stored data frame. Function tailored German texts.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/clean_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clean text — clean_text","text":"","code":"clean_text(   df,   text_field = \"text\",   clean_field = \"text\",   tolower = T,   remove_punct = T,   simplify_punct = F,   replace_emojis = T,   replace_numbers = T,   remove_stopwords = F,   store_uncleaned = T,   count = T )"},{"path":"https://thieled.github.io/dictvectoR/reference/clean_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clean text — clean_text","text":"df data frame. text_field character. Default 'text'. Name column df contains text cleaned. Default 'text'. clean_field character. Default 'text'. Name given new column df contain cleaned text. tolower logical. Lowercase text? Default TRUE. remove_punct logical. Remove punctuation?  Default TRUE. simplify_punct logical. Replace !, :, ?, ... single . Default FALSE. replace_emojis logical. Replace list emojis German words certain emotions ('wut', 'angst', 'freude'). Default TRUE. replace_numbers logical. Replace numbers German words numbers. Default TRUE. remove_stopwords logical. Remove German stopwords 'nltk' list exception words defined author. Default FALSE. store_uncleaned logical. Save uncleaned text 'uncleaned_text' column? Default TRUE. count logical. Count number words strings cleaning? create columns 'n_words' 'n_chars'. Default TRUE.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/clean_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clean text — clean_text","text":"data.frame columns df. cleaned text column specified text_field , specified 'text.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/clean_text.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clean text — clean_text","text":"","code":"tw_data %<>% head(10) %>% clean_text(text_field = 'full_text') tw_data$text #>  [1] \"es geht bei dieser richtungswahl um die frage bleiben wir auf einem kurs der mitte und der stabilität oder bekommen wir ein rot grün rotes abenteuer mit unabsehbaren konsequenzen für arbeitsplätze den wohlstand unseres landes und die zukunft unserer kinder tm merzmail\"       #>  [2] \"aus vielen veranstaltungen der letzten wochen nehme ich den eindruck mit die stimmung für cdu und csu ist besser als die umfragen darin liegt jetzt unsere chance bitte gehen sie alle morgen wählen und geben sie beide stimmen der union tm merzmail unionstärkstekraft\"          #>  [3] \"sendung verpasst sehen sie hier die diskussion zwischen friedrich merz und hubertus heil bei sandra maischberger in der ard mediathek ab ca neunzehn tm\"                                                                                                                            #>  [4] \"ich bin mir nicht sicher ob wir corona einschränkungen wie die maskenpflicht noch brauchen wir sehen in ländern die rascher gelockert haben niedrige inzidenzen und hospitalisierungsquoten und wir sehen wie viel gesellschaftlichen dissens die maßnahmen verursachen tm\"         #>  [5] \"frau nahles hatte recht der mechanismus der mindestlohnkommission ist wichtig damit der mindestlohn kein wahlkampfthema wird der vorschlag für zwölf euro mindestlohn ist rein populistisch jetzt startet ein politischer überbietungswettbewerb zwischen spd und linkspartei tm\"   #>  [6] \"ich war immer für den mindestlohn die entscheidende frage ist wer ihn in zukunft festlegt die tarifvertragsparteien oder der gesetzgeber aus meiner sicht sollte dieses thema in der mindestlohnkommission bleiben und gehört nicht in den bundestag tm merz maischberger\"          #>  [7] \"die oberen zehn der steuerpflichtigen bezahlen mehr als fünfzig des einkommenssteueraufkommens zu behaupten dass sich diese menschen nicht genug an der finanzierung des gemeinwesens beteiligen ist unseriös wir haben die höchsten steuern und abgaben in europa tm maischberger\" #>  [8] \"die vollständige abschaffung des solidaritätszuschlags ist eine frage des respekts und der fairness gegenüber all denjenigen die dreißig jahre lang die deutsche einheit finanziert haben alles andere ist ein gebrochenes versprechen des steuergesetzgebers tm maischberger merz\" #>  [9] \"die cdu hat damals als oppositionspartei der agenda tausende der spd zugestimmt wir sehen es mit bedauern dass diese reformen von den sozialdemokraten schritt für schritt wieder zurückgenommen werden wir müssen zurückkehren zum prinzip fördern und fordern tm maischberger\"    #> [10] \"von analog tausende zu digital tausende schauen sie mal was mein team und ich heute zum abschluss des wahlkampfes im hochsauerlandkreis online gestellt haben leiten sie das video auch gerne an freunde und bekannte weiter hier geht s zum download\""},{"path":"https://thieled.github.io/dictvectoR/reference/compound.html","id":null,"dir":"Reference","previous_headings":"","what":"Assignment pipe — %<>%","title":"Assignment pipe — %<>%","text":"See magrittr::%<>% details.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/compound.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assignment pipe — %<>%","text":"lhs object serves initial value target. rhs function call using magrittr semantics.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/confuse.html","id":null,"dir":"Reference","previous_headings":"","what":"Get confusion matrix — confuse","title":"Get confusion matrix — confuse","text":"Returns confusion matrix validation scores binary reference variable, binary prediction variable.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/confuse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get confusion matrix — confuse","text":"","code":"confuse(reference, prediction)"},{"path":"https://thieled.github.io/dictvectoR/reference/confuse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get confusion matrix — confuse","text":"reference binary reference vector. prediction binary prediction vector.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/confuse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get confusion matrix — confuse","text":"confusionMatrix object caret::confusionMatrix().","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/confuse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get confusion matrix — confuse","text":"values reference prediction must 0 1. variables can stored data.frame vectors equal length. Can type numeric factor.","code":""},{"path":[]},{"path":"https://thieled.github.io/dictvectoR/reference/confuse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get confusion matrix — confuse","text":"","code":"mtcars$pred <- get_prediction(mtcars, mtcars$am, mtcars$drat) confuse(mtcars$am, mtcars$pred) #> Confusion Matrix and Statistics #>  #>     #>      0  1 #>   0 16  2 #>   1  3 11 #>                                            #>                Accuracy : 0.8438           #>                  95% CI : (0.6721, 0.9472) #>     No Information Rate : 0.5938           #>     P-Value [Acc > NIR] : 0.002273         #>                                            #>                   Kappa : 0.68             #>                                            #>  Mcnemar's Test P-Value : 1.000000         #>                                            #>               Precision : 0.7857           #>                  Recall : 0.8462           #>                      F1 : 0.8148           #>              Prevalence : 0.4062           #>          Detection Rate : 0.3438           #>    Detection Prevalence : 0.4375           #>       Balanced Accuracy : 0.8441           #>                                            #>        'Positive' Class : 1                #>"},{"path":"https://thieled.github.io/dictvectoR/reference/cossim2dict.html","id":null,"dir":"Reference","previous_headings":"","what":"Similarity of documents to a dictionary — cossim2dict","title":"Similarity of documents to a dictionary — cossim2dict","text":"Computes cosinal similarity average word vector representation document data frame average word vector representation dictionary, using fasttext word vector model.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/cossim2dict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Similarity of documents to a dictionary — cossim2dict","text":"","code":"cossim2dict(   df,   dictionary,   model,   text_field = \"text\",   replace_na = c(\"mean-sd\", \"min\", 0, F) )"},{"path":"https://thieled.github.io/dictvectoR/reference/cossim2dict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Similarity of documents to a dictionary — cossim2dict","text":"df dataframe containing one document per row. dictionary character vector containing keywords dictionary. model fasttext model loaded load_model. text_field Name column df contains text documents. Default \"text\". replace_na Specifies value used replace NAs. Default 'mean-sd'. Can take values: 'mean-sd' (charcter): replace NAs mean - 1sd. Default. 'min' (charcter): replace NAs minimum. 0 (numerical): replace NAs 0. FALSE (logical): replace NAs.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/cossim2dict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Similarity of documents to a dictionary — cossim2dict","text":"Numerical. Cosinal similarity, ranging (theoretically) -1 +1. Indicating similarity average fasttext word vector words dictionary average fasttext word vector document df.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/cossim2dict.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Similarity of documents to a dictionary — cossim2dict","text":"Implements method called 'Distributed Dictionary Representation' (DDR), introduced Garten et al. (2018). average dictionary vector calculated mean vector words dictioary, stored character vector. document vectors calculated mean vectors words per observation column named 'text' dataframe. One row dataframe represents one document. , average dictionary vector document vectors L2 normalized. function returns cosinal similarity dictionary vector document dataframe.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/cossim2dict.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Similarity of documents to a dictionary — cossim2dict","text":"Garten, J., Hoover, J., Johnson, K. M., Boghrati, R., Iskiwitch, C., & Dehghani, M. (2018). Dictionaries distributions: Combining expert knowledge large scale textual data content analysis. Behavior Research Methods, 50(1), 344 - 361. https://doi.org/10.3758/s13428-017-0875-9","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/cossim2dict.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Similarity of documents to a dictionary — cossim2dict","text":"","code":"model <- fastrtext::load_model(system.file(\"extdata\", \"tw_demo_model_sml.bin\", package = \"dictvectoR\")) tw_annot %<>% head(100) %>% clean_text(remove_stopwords = TRUE,                                        text_field = \"full_text\") dict <- c(\"skandal\", \"deutschland\", \"steuerzahler\") tw_annot$ddr <- cossim2dict(tw_annot, dict, model)"},{"path":"https://thieled.github.io/dictvectoR/reference/detect_similar_words.html","id":null,"dir":"Reference","previous_headings":"","what":"Detect similar words — detect_similar_words","title":"Detect similar words — detect_similar_words","text":"Detects similar words data.frame, using fastText model. requested, compares similar words along variable specified compare_by, number occurrences stored variable named hits. Counts often one word 'beats' similar pairwise comparison. count returned 'wins_'.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/detect_similar_words.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detect similar words — detect_similar_words","text":"","code":"detect_similar_words(   word_df,   model,   word_field = \"words\",   compare_by = NULL,   compare_hits = T,   min_simil = 0.7 )"},{"path":"https://thieled.github.io/dictvectoR/reference/detect_similar_words.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Detect similar words — detect_similar_words","text":"word_df data.frame containing column words multi-word expressions. model fastText model, loaded load_model. word_field Character. name column word_df contains words. compare_by Character. Default NULL. name column compared. compare_hits Logical. Default TRUE. true counts often one word 'beats' similar regard occurrences. min_simil Numerical (0-1). Default .7. Similarity threshold. Word pairs threshold considered dissimilar.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/detect_similar_words.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Detect similar words — detect_similar_words","text":"data.frame. Containing pairwise similarity table similar words.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/detect_similar_words.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Detect similar words — detect_similar_words","text":"Forces 'word_df' unique identifying variable called 'word_id'; re-uses variable named 'id' unique.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/detect_similar_words.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Detect similar words — detect_similar_words","text":"","code":"model <- fastrtext::load_model(system.file(\"extdata\", \"tw_demo_model_sml.bin\", package = \"dictvectoR\")) word_df <- data.frame(words = c(\"unsere steuern\", \"steuerzahler\",  \"unsere\",  \"steuern\"), hits = c(2, 3, 15, 4)) detect_similar_words(word_df, model) #> Warning: undefined subclass \"unpackedMatrix\" of class \"mMatrix\"; definition not updated #> Warning: undefined subclass \"unpackedMatrix\" of class \"replValueSp\"; definition not updated #>       simil word_id1          word1 hits1 word_id2          word2 hits2 #> 1 0.8014612        3         unsere    15        1 unsere steuern     2 #> 2 0.8014612        4        steuern     4        1 unsere steuern     2 #> 3 0.8445002        4        steuern     4        2   steuerzahler     3 #> 4 0.8014612        1 unsere steuern     2        3         unsere    15 #> 5 0.8014612        1 unsere steuern     2        4        steuern     4 #> 6 0.8445002        2   steuerzahler     3        4        steuern     4 #>   wins_hits1 #> 1          1 #> 2          1 #> 3          1 #> 4          0 #> 5          0 #> 6          0"},{"path":"https://thieled.github.io/dictvectoR/reference/drop_which.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine which similar terms to drop — drop_which","title":"Determine which similar terms to drop — drop_which","text":"Takes pairwise similarity table returned detect_similar_words. Returns data.frame terms dropped according specified decision rules. function can compare words similarity table along two aspects: number comparison wins regarding score specified 'compare_by' detect_similar_words, resp. remove_similar_words. variable must stored similarity table 'wins_score1. number comparison wins regarding frequency occurrences, set 'compare_hits = T' detect_similar_words, resp. remove_similar_words. variable must stored similarity table 'wins_hits1. variables can compared time. 'wins_score1' missing, function compare 'hits'.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/drop_which.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Determine which similar terms to drop — drop_which","text":"","code":"drop_which(simil_table, compare_hits = T, win_threshold = 0.5)"},{"path":"https://thieled.github.io/dictvectoR/reference/drop_which.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determine which similar terms to drop — drop_which","text":"simil_table data.frame. pairwise similarity table returned detect_similar_words. compare_hits logical. Default TRUE. TRUE, consider 'hits' comparison. win_threshold Numerical (0-1). Default .5. Determines threshold drop words, defined proportion won pairwise comparisons. hits scores compared, mean proportions. Words suggested dropping computed value smaller value set .","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/drop_which.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine which similar terms to drop — drop_which","text":"data.frame words suggested dropping.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/drop_which.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Determine which similar terms to drop — drop_which","text":"","code":"model <- fastrtext::load_model(system.file(\"extdata\",                                           \"tw_demo_model_sml.bin\",                                            package = \"dictvectoR\")) set.seed(1) word_df <- data.frame(words = c(\"unsere steuern\", \"steuerzahler\",                                \"unsere\", \"steuern\"), hits = c(2, 3, 15, 4), score = rnorm(4)) sim_t <- detect_similar_words(word_df, model, compare_by = \"score\") drop_which(sim_t, compare_hits = TRUE, win_threshold = .4) #> # A tibble: 2 × 6 #>   word_id1 words          word_id wins_score_pct wins_hits_pct   win #>   <chr>    <chr>          <chr>            <dbl>         <dbl> <dbl> #> 1 1        unsere steuern 1                  0.5             0  0.25 #> 2 2        steuerzahler   2                  0               0  0"},{"path":"https://thieled.github.io/dictvectoR/reference/filter_ntile.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter by ntile. — filter_ntile","title":"Filter by ntile. — filter_ntile","text":"Filter data frame top quantile specified variable.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/filter_ntile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter by ntile. — filter_ntile","text":"","code":"filter_ntile(df, var_field, probs)"},{"path":"https://thieled.github.io/dictvectoR/reference/filter_ntile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter by ntile. — filter_ntile","text":"df data.frame. var_field character string indicating name variable used filtering. probs numerical value 0 1 (.e. proportion) indicating quantile threshold used filtering.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/filter_ntile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter by ntile. — filter_ntile","text":"data.frame, containing rows specified variable greater equal specified threshold.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/filter_ntile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter by ntile. — filter_ntile","text":"","code":"df <- data.frame(a = rnorm(10), b = sample(letters, 10, replace = TRUE)) filter_ntile(df, \"a\", .75) #>           a b #> 4 0.7383247 y #> 5 0.5757814 l #> 7 1.5117812 a"},{"path":"https://thieled.github.io/dictvectoR/reference/find_distinctive.html","id":null,"dir":"Reference","previous_headings":"","what":"Find distinctive keywords — find_distinctive","title":"Find distinctive keywords — find_distinctive","text":"Compares word-vector representations words representations annotated data.frame texts. Aims detect words distinctively characterize concept.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/find_distinctive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find distinctive keywords — find_distinctive","text":"","code":"find_distinctive(   df,   concept_field,   text_field = \"text\",   word_df,   word_field = \"words\",   model )"},{"path":"https://thieled.github.io/dictvectoR/reference/find_distinctive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find distinctive keywords — find_distinctive","text":"df data.frame containing one annotated document per row. concept_field character. Name column contains binary, (hand-coded) indicator presence absence concept. text_field character. Name column df contains text documents. Default \"text\". word_df data.frame containing column words multi-word expressions. word_field character. name column word_df contains words. model fastText model, loaded fastrtext::load_model().","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/find_distinctive.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find distinctive keywords — find_distinctive","text":"Takes annotated data.frame df texts input. varialbe specified concept_field df indicates presence absence theoretical concept text. Two average word-vector representations computed, using fastText model: One texts contain concept, one . second data.frame, word_df, contains one (multi-)word per row 'word_field'. Three new columns word_df created: first, ending '_possim', indicates cosine similarity word positive concept corpus. second '_negsim', indicates similarity remaining corpus. third, ending '_distinctive' difference two.","code":""},{"path":[]},{"path":"https://thieled.github.io/dictvectoR/reference/find_distinctive.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find distinctive keywords — find_distinctive","text":"","code":"model <- fastrtext::load_model(system.file(\"extdata\",                                \"tw_demo_model_sml.bin\",                                 package = \"dictvectoR\")) tw_annot %<>% clean_text(text_field = \"full_text\") word_df <- data.frame(words = c(\"skandal\", \"deutschland\", \"wundervoll\")) find_distinctive(tw_annot,                  \"pop\",                   word_df = word_df,                   model = model) #>         words pop_possim pop_negsim pop_distinctive #> 1     skandal  0.5809499  0.5490425      0.03190745 #> 2 deutschland  0.7616619  0.7402692      0.02139269 #> 3  wundervoll  0.6919564  0.7408727     -0.04891631"},{"path":"https://thieled.github.io/dictvectoR/reference/find_unique_id.html","id":null,"dir":"Reference","previous_headings":"","what":"Find index of unique id in df. — find_unique_id","title":"Find index of unique id in df. — find_unique_id","text":"Searches data.frame column includes 'id' name unique identifier. Returns index first column data.frame meets conditions.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/find_unique_id.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find index of unique id in df. — find_unique_id","text":"","code":"find_unique_id(df)"},{"path":"https://thieled.github.io/dictvectoR/reference/find_unique_id.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find index of unique id in df. — find_unique_id","text":"df data.frame.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/find_unique_id.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find index of unique id in df. — find_unique_id","text":"numeric, indicating index unique id column.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/find_unique_id.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find index of unique id in df. — find_unique_id","text":"","code":"df <- data.frame(id_not_unique = rep(1, 10), unique_id = 1:10, also_id = 21:30, other = letters[1:10]) find_unique_id(df) #> [1] 2"},{"path":"https://thieled.github.io/dictvectoR/reference/get_ARPF.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Accuracy, Recall, Precision, and F1 — get_ARPF","title":"Get Accuracy, Recall, Precision, and F1 — get_ARPF","text":"Returns Accuracy, Recall, Precision, F1 scores binary reference variable binary prediction variable.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_ARPF.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Accuracy, Recall, Precision, and F1 — get_ARPF","text":"","code":"get_ARPF(reference, prediction)"},{"path":"https://thieled.github.io/dictvectoR/reference/get_ARPF.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Accuracy, Recall, Precision, and F1 — get_ARPF","text":"reference binary reference vector. prediction binary prediction vector.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_ARPF.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Accuracy, Recall, Precision, and F1 — get_ARPF","text":"data.frame columns 'accuracy', 'recall', 'precision', 'F1'.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_ARPF.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Accuracy, Recall, Precision, and F1 — get_ARPF","text":"values reference prediction must 0 1. variables can stored data.frame vectors equal length. Can type numeric factor.","code":""},{"path":[]},{"path":"https://thieled.github.io/dictvectoR/reference/get_ARPF.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Accuracy, Recall, Precision, and F1 — get_ARPF","text":"","code":"mtcars$pred <- get_prediction(mtcars, mtcars$am, mtcars$drat) get_ARPF(mtcars$am, mtcars$pred) #>   accuracy    recall precision        F1 #> 1  0.84375 0.8461538 0.7857143 0.8148148"},{"path":"https://thieled.github.io/dictvectoR/reference/get_F1.html","id":null,"dir":"Reference","previous_headings":"","what":"Get F1 score for a DDR measure — get_F1","title":"Get F1 score for a DDR measure — get_F1","text":"Returns F1 score DDR measurement predicting binary reference (.e. manually annotated variable).","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_F1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get F1 score for a DDR measure — get_F1","text":"","code":"get_F1(   df,   dictionary,   model,   reference,   text_field = \"text\",   replace_na = c(\"mean-sd\", \"min\", 0, F) )"},{"path":"https://thieled.github.io/dictvectoR/reference/get_F1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get F1 score for a DDR measure — get_F1","text":"df data.frame containing one annotated document sentence per row. dictionary character vector containing keywords dictionary, passed cossim2dict. model fasttext model loaded load_model. reference Name binary reference column df. text_field Name column df contains text documents. Default \"text\". replace_na Specifies value used replace NAs DDR measurement. Default 'mean-sd'. Can take values: 'mean-sd' (charcter): replace NAs mean - 1sd. Default. 'min' (charcter): replace NAs minimum. 0 (numerical): replace NAs 0. FALSE (logical): replace NAs.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_F1.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get F1 score for a DDR measure — get_F1","text":"gradual DDR measurement passed get_prediction() obtain binary prediction logistic regression. F1 scores indicate performance words/dictionaries predicting binary coding, used DDR method. F1 score harmonic mean Recall Precision (1).","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_F1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Get F1 score for a DDR measure — get_F1","text":"(1) Chinchor, N. (1992). MUC-4 evaluation metrics. Proceedings 4th Conference Message Understanding, 22–29. https://doi.org/10.3115/1072064.1072067","code":""},{"path":[]},{"path":"https://thieled.github.io/dictvectoR/reference/get_F1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get F1 score for a DDR measure — get_F1","text":"","code":"model <- fastrtext::load_model(system.file(\"extdata\",                                \"tw_demo_model_sml.bin\",                                 package = \"dictvectoR\")) tw_annot %<>% clean_text(text_field = \"full_text\") dict <- c(\"skandal\", \"deutschland\", \"steuerzahler\") get_F1(tw_annot, dict, model, 'pop') #> [1] 0.2897527"},{"path":"https://thieled.github.io/dictvectoR/reference/get_combis.html","id":null,"dir":"Reference","previous_headings":"","what":"Get combinations of keywords — get_combis","title":"Get combinations of keywords — get_combis","text":"Returns combinations keywords.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_combis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get combinations of keywords — get_combis","text":"","code":"get_combis(   word_df,   word_field = \"words\",   dims = NULL,   min_per_dim = 1,   max_overall,   limit = NULL,   seed = 1,   save_settings = T,   save_input = F )"},{"path":"https://thieled.github.io/dictvectoR/reference/get_combis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get combinations of keywords — get_combis","text":"word_df data.frame containing column words multi-word expressions. word_field character. Default 'words'. name column word_df contains words. dims character. Default NULL. name column word_df groups words dimensions. Can ignored. min_per_dim numerical. Default 1. Minimum number words (per dimension) returned. replaced 1 < 1. max_overall numerical. Maximum number words per returned combination. limit numerical. Default NULL. Limits number combinations equal length per dimension randomization. seed numerical. Default 1. Input make randomization reproducible. save_settings logical. Default TRUE. Saves randomization settings df make reproducible. save_input logical. Default FALSE. Saves input words dims df character string.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_combis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get combinations of keywords — get_combis","text":"data.frame combinations. combinations stored list character vectors combs_split. Use column pass get_many_F1s get_many_RPFs. data.frame include string variables words combinations called combs dimension. use columns passing dictionaries get_many_F1s, result faulty average representation, caused representations multi-word expressions queried. Additionally, data.frame includes rowid, count variable number words overall (sum_nterms), counts dimension, can used remove imbalanced dictionaries. requested, settings stores randomization settings, input words dimensions used input.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_combis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get combinations of keywords — get_combis","text":"Takes data.frame word_df character column specified words input. default, return combinations various lengths words. Additionally, function can account conceptual dimensions, identified categorical (character, numerical, factor) column word_df specified dims. dimensions specified, function find combinations dimension, return combinations combinations. CAUTION: can lead quickly extremely large number combinations. number combinations can limited several ways: Firstly, minimum number words returned per dimension specified min_per_dim, maximum number words overall set max_overall. Secondly, function allows random sampling combinations. recommended, drastically reduces number returned combinations, reduces computational load, speeds process. (course, comes cost completeness). Random sampling implemented using comboSample function. Setting limit cap number combinations equal length dimension. E.g., limit = 5, min_per_dim = 2, max_overall = 6 set word_df containing two dimensions b, function pick max. five combinations length 2 , five length 2 b, five length 3 , five length 3 b, return combinations combinations.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_combis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get combinations of keywords — get_combis","text":"","code":"test_df <- data.frame(words = letters[1:8],                       dim = rep(paste0(\"c_\", 1:2), 4)) t0 <- get_combis(test_df,                  word_field = \"words\",                  dims = \"dim\",                  max_overall = 5) #> Joining, by = \"rowid\" t1 <- get_combis(test_df,                  word_field = \"words\",                  dims = \"dim\",                  max_overall = 5,                  limit = 5) #> Joining, by = \"rowid\""},{"path":"https://thieled.github.io/dictvectoR/reference/get_corpus_representation.html","id":null,"dir":"Reference","previous_headings":"","what":"Vector representation of a corpus. — get_corpus_representation","title":"Vector representation of a corpus. — get_corpus_representation","text":"Returns average word-vector representation text column data frame, using fastText model.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_corpus_representation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Vector representation of a corpus. — get_corpus_representation","text":"","code":"get_corpus_representation(df, model, text_field = \"text\", normalize = T)"},{"path":"https://thieled.github.io/dictvectoR/reference/get_corpus_representation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Vector representation of a corpus. — get_corpus_representation","text":"df data.frame column containing text identified text_field. model fastText model, loaded fastrtext::load_model(). text_field character string indicating name text column df. normalize Logical. Default TRUE. Normalize vectors Euclidean norm?","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_corpus_representation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Vector representation of a corpus. — get_corpus_representation","text":"single-row sparse matrix class dgCMatrix returned Matrix.","code":""},{"path":[]},{"path":"https://thieled.github.io/dictvectoR/reference/get_corpus_representation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Vector representation of a corpus. — get_corpus_representation","text":"","code":"model <- fastrtext::load_model(system.file(\"extdata\",                                            \"tw_demo_model_sml.bin\",                                             package = \"dictvectoR\")) tw_annot <- tw_annot %>% head(15) %>% clean_text(text_field = \"full_text\") corpus_rep <- get_corpus_representation(tw_annot, model)"},{"path":"https://thieled.github.io/dictvectoR/reference/get_hits.html","id":null,"dir":"Reference","previous_headings":"","what":"Get occurrence frequency of words. — get_hits","title":"Get occurrence frequency of words. — get_hits","text":"Adds number occurrences word multi-word expression quanteda tokens object data.frame. default, checks 'hits' counted fills missing values. Works GLOB-style wildcards.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_hits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get occurrence frequency of words. — get_hits","text":"","code":"get_hits(word_df, tokens, word_field = \"words\", replace = F)"},{"path":"https://thieled.github.io/dictvectoR/reference/get_hits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get occurrence frequency of words. — get_hits","text":"word_df data.frame containing words. tokens word-tokens object, returned quanteda::tokens. word_field Character. Default \"words\". Name column word_df contains words. replace Logical. Default FALSE. FALSE checks fills 'hits' missing observations. TRUE counts 'hits' words word_df.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_hits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get occurrence frequency of words. — get_hits","text":"data.frame column 'hits' indicating frequency term tokens. Arranged descending number hits.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_hits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get occurrence frequency of words. — get_hits","text":"","code":"tw_data %<>% head(100) %>% clean_text(text_field = 'full_text') toks <- quanteda::tokens(tw_data$text) word_df <- data.frame(words = c(\"der deutschen\", \"steuer*\", \"xyz\")) %>% get_hits(tokens = toks) #> [1] \"Counting word occurrences...\""},{"path":"https://thieled.github.io/dictvectoR/reference/get_many_F1s.html","id":null,"dir":"Reference","previous_headings":"","what":"Get F1 scores for many words or dictionaries. — get_many_F1s","title":"Get F1 scores for many words or dictionaries. — get_many_F1s","text":"Efficiently computes F1 scores elements vector containing keywords, list containing dictionaries, used DDR method.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_many_F1s.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get F1 scores for many words or dictionaries. — get_many_F1s","text":"","code":"get_many_F1s(   words,   model,   df,   reference,   text_field = \"text\",   replace_na = c(\"mean-sd\", \"min\", 0, F) )"},{"path":"https://thieled.github.io/dictvectoR/reference/get_many_F1s.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get F1 scores for many words or dictionaries. — get_many_F1s","text":"words character vector containing keywords, list character vectors containing dictionaries. model fastText model, loaded fastrtext::load_model(). df data.frame containing one annotated document per row. reference Name binary reference column df (character). text_field Name column df contains text documents. Default \"text\". replace_na Specifies value used replace NAs DDR measurement. Default 'mean-sd'. Can take values: 'mean-sd' (charcter): replace NAs mean - 1sd. Default. 'min' (charcter): replace NAs minimum. 0 (numerical): replace NAs 0. FALSE (logical): replace NAs.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_many_F1s.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get F1 scores for many words or dictionaries. — get_many_F1s","text":"numerical F1 score returned element (.e. word dictionary) vector list. F1 scores indicate performance words/dictionaries predicting binary coding, used DDR method. resulting gradual measure DDR measure passed logistic regression, binary coding dependent variable. Binary predictions calculated logistic model compared binary coding. F1 score harmonic mean Recall Precision (1).","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_many_F1s.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Get F1 scores for many words or dictionaries. — get_many_F1s","text":"(1) Chinchor, N. (1992). MUC-4 evaluation metrics. Proceedings 4th Conference Message Understanding, 22–29. https://doi.org/10.3115/1072064.1072067","code":""},{"path":[]},{"path":"https://thieled.github.io/dictvectoR/reference/get_many_F1s.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get F1 scores for many words or dictionaries. — get_many_F1s","text":"","code":"model <- fastrtext::load_model(system.file(\"extdata\",                                \"tw_demo_model_sml.bin\",                                 package = \"dictvectoR\")) tw_annot %<>% clean_text(text_field = \"full_text\") dict_df <- data.frame(id = 1:3) dict_df$combis <- list(c(\"mehrheit deutschen\", \"merkel\", \"skandal\"),                       c(\"steuerzahler\", \"bundesregierung\",                       \"komplett gescheitert\"),                       c( \"arbeitnehmer\", \"groko\", \"wahnsinn\")) dict_df$F1 <- get_many_F1s(dict_df$combis,                            model = model,                            df = tw_annot,                            reference = \"pop\")"},{"path":"https://thieled.github.io/dictvectoR/reference/get_many_F1s_by_group.html","id":null,"dir":"Reference","previous_headings":"","what":"Get F1 for many by a grouping varialbe — get_many_F1s_by_group","title":"Get F1 for many by a grouping varialbe — get_many_F1s_by_group","text":"Efficiently computes F1 scores character vector keywords stored data.frame, list dictionaries stored data.frame - reference data.frame grouped group_field. ADD DETAILS....","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_many_F1s_by_group.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get F1 for many by a grouping varialbe — get_many_F1s_by_group","text":"","code":"get_many_F1s_by_group(   keyword_df,   keyword_field = \"words\",   id = \"id\",   model,   text_df,   group_field,   reference,   text_field = \"text\",   replace_na = c(\"mean-sd\", \"min\", 0, F) )"},{"path":"https://thieled.github.io/dictvectoR/reference/get_many_F1s_by_group.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get F1 for many by a grouping varialbe — get_many_F1s_by_group","text":"keyword_df data.frame, containing column character vector words, list dictionaries. keyword_field character. name column keyword_df either character vector single keywords, list dictionaries, stored separate character vectors one element per word. id unique identifier keyword. model fastText model, loaded load_model. text_df data.frame containing one annotated document per row. group_field character. Name categorical grouping variable df. reference character. Name binary reference column df. text_field Name column df contains text documents. Default \"text\". replace_na Specifies value used replace NAs DDR measurement. Default 'mean-sd'. Can take values: 'mean-sd' (charcter): replace NAs mean - 1sd. Default. 'min' (charcter): replace NAs minimum. 0 (numerical): replace NAs 0. FALSE (logical): replace NAs.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_many_F1s_by_group.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get F1 for many by a grouping varialbe — get_many_F1s_by_group","text":"#'@seealso cossim2dict, get_prediction, get_F1, get_many_RPFs, confusionMatrix","code":""},{"path":[]},{"path":"https://thieled.github.io/dictvectoR/reference/get_many_F1s_by_group.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get F1 for many by a grouping varialbe — get_many_F1s_by_group","text":"","code":"model <- fastrtext::load_model(system.file(\"extdata\",                                \"tw_demo_model_sml.bin\",                                 package = \"dictvectoR\")) tw_annot %<>% clean_text(text_field = \"full_text\") dict_df <- data.frame(id = 1:3) dict_df$combis <- list(c(\"mehrheit deutschen\", \"merkel\", \"skandal\"),                       c(\"steuerzahler\", \"bundesregierung\",                       \"komplett gescheitert\"),                       c( \"arbeitnehmer\", \"groko\", \"wahnsinn\")) get_many_F1s_by_group(keyword_df = dict_df,                      keyword_field = \"combis\",                      id = \"id\",                      model = model,                      text_df = tw_annot,                      group_field = \"party\",                      reference = 'pop') #> Joining, by = \"id\" #>   id                                              combis    F1_AfD F1_B90Grune #> 1  1                 mehrheit deutschen, merkel, skandal 0.6447368           0 #> 2  2 steuerzahler, bundesregierung, komplett gescheitert 0.6666667           0 #> 3  3                       arbeitnehmer, groko, wahnsinn 0.6953642           0 #>   F1_CDU F1_CSU F1_FDP  F1_Linke F1_SPD #> 1      0      0      0 0.0000000      0 #> 2      0      0      0 0.4210526      0 #> 3      0      0      0 0.3548387      0"},{"path":"https://thieled.github.io/dictvectoR/reference/get_many_RPFs.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Recall, Precision, F1 for many — get_many_RPFs","title":"Get Recall, Precision, F1 for many — get_many_RPFs","text":"Efficiently computes Recall, Precision, F1 scores character vector keywords stored data.frame, list dictionaries stored data.frame. Adds Recall, Precision, F1 data.frame.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_many_RPFs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Recall, Precision, F1 for many — get_many_RPFs","text":"","code":"get_many_RPFs(   keyword_df,   keyword_field = \"words\",   model,   text_df,   reference,   text_field = \"text\",   replace_na = c(\"mean-sd\", \"min\", 0, F) )"},{"path":"https://thieled.github.io/dictvectoR/reference/get_many_RPFs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Recall, Precision, F1 for many — get_many_RPFs","text":"keyword_df data.frame, containing column character vector words, list dictionaries. keyword_field character. name column keyword_df either character vector single keywords, list dictionaries, stored separate character vectors one element per word. model fastText model, loaded load_model. text_df data.frame containing one annotated document per row. reference Name binary reference column df (character). text_field Name column df contains text documents. Default \"text\". replace_na Specifies value used replace NAs DDR measurement. Default 'mean-sd'. Can take values: 'mean-sd' (charcter): replace NAs mean - 1sd. Default. 'min' (charcter): replace NAs minimum. 0 (numerical): replace NAs 0. FALSE (logical): replace NAs.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_many_RPFs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Recall, Precision, F1 for many — get_many_RPFs","text":"element (.e. word dictionary) character vector list data.frame . F1 scores indicate performance words/dictionaries predicting binary coding, used DDR method. resulting gradual measure DDR measure passed logistic regression, binary coding dependent variable. Binary predictions calculated logistic model compared binary coding. F1 score harmonic mean Recall Precision (Chinchor, 1992).","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_many_RPFs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Get Recall, Precision, F1 for many — get_many_RPFs","text":"Chinchor, N. (1992). MUC-4 evaluation metrics. Proceedings 4th Conference Message Understanding, 22–29. https://doi.org/10.3115/1072064.1072067","code":""},{"path":[]},{"path":"https://thieled.github.io/dictvectoR/reference/get_many_RPFs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Recall, Precision, F1 for many — get_many_RPFs","text":"","code":"model <- fastrtext::load_model(system.file(\"extdata\",                                \"tw_demo_model_sml.bin\",                                 package = \"dictvectoR\")) tw_annot %<>% clean_text(text_field = \"full_text\") dict_df <- data.frame(id = 1:3) dict_df$combis <- list(c(\"mehrheit deutschen\", \"merkel\", \"skandal\"),                       c(\"steuerzahler\", \"bundesregierung\",                       \"komplett gescheitert\"),                       c( \"arbeitnehmer\", \"groko\", \"wahnsinn\")) get_many_RPFs(keyword_df = dict_df,        keyword_field = \"combis\",        model = model,        text_df = tw_annot, reference = \"pop\") #> Joining, by = \"rowid\" #>   id                                              combis     recall precision #> 1  1                 mehrheit deutschen, merkel, skandal 0.08796296 0.5428571 #> 2  2 steuerzahler, bundesregierung, komplett gescheitert 0.16666667 0.6101695 #> 3  3                       arbeitnehmer, groko, wahnsinn 0.05092593 0.6111111 #>           F1 #> 1 0.15139442 #> 2 0.26181818 #> 3 0.09401709"},{"path":"https://thieled.github.io/dictvectoR/reference/get_prediction.html","id":null,"dir":"Reference","previous_headings":"","what":"Get binary prediction — get_prediction","title":"Get binary prediction — get_prediction","text":"Returns prediction binary variable gradual measurement using logistic regression.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_prediction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get binary prediction — get_prediction","text":"","code":"get_prediction(data, dv, iv)"},{"path":"https://thieled.github.io/dictvectoR/reference/get_prediction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get binary prediction — get_prediction","text":"data data frame. dv binary variable data frame. iv gradual variable data frame used predicting dv.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_prediction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get binary prediction — get_prediction","text":"factor levels 0, 1.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_prediction.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get binary prediction — get_prediction","text":"Predictions considered '1' predicted probability >= .5.","code":""},{"path":[]},{"path":"https://thieled.github.io/dictvectoR/reference/get_prediction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get binary prediction — get_prediction","text":"","code":"data(mtcars) mtcars$pred <- get_prediction(mtcars, mtcars$am, mtcars$drat)"},{"path":"https://thieled.github.io/dictvectoR/reference/get_word_representations.html","id":null,"dir":"Reference","previous_headings":"","what":"Get word representations. — get_word_representations","title":"Get word representations. — get_word_representations","text":"Wrapper around get_sentence_representation return fastText word-vector representation words multiwords, stored column data frame 'word_df.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_word_representations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get word representations. — get_word_representations","text":"","code":"get_word_representations(word_df, model, word_field = \"words\", normalize = T)"},{"path":"https://thieled.github.io/dictvectoR/reference/get_word_representations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get word representations. — get_word_representations","text":"word_df data.frame containing column words multiword expressions. model fastText model, loaded fastrtext::load_model(). word_field character string indicating name column word_df contains words. normalize Logical. Default TRUE. Normalize vectors Euclidean norm?","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/get_word_representations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get word representations. — get_word_representations","text":"sparse matrix class dgCMatrix returned Matrix. number rows word_df number columns dimensions model.","code":""},{"path":[]},{"path":"https://thieled.github.io/dictvectoR/reference/get_word_representations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get word representations. — get_word_representations","text":"","code":"model <- fastrtext::load_model(system.file(\"extdata\",                                            \"tw_demo_model_sml.bin\",                                             package = \"dictvectoR\")) word_df <- data.frame(words = c(\"das ist\", \"ein\", \"test\")) word_rep <- get_word_representations(word_df, model)"},{"path":"https://thieled.github.io/dictvectoR/reference/normalize.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize a vector — normalize","title":"Normalize a vector — normalize","text":"Normalizes (matrix) vector Euclidean norm, 'L2'-norm.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/normalize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize a vector — normalize","text":"","code":"normalize(x)"},{"path":"https://thieled.github.io/dictvectoR/reference/normalize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize a vector — normalize","text":"x numeric vector, matrix vectors.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/normalize.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normalize a vector — normalize","text":"norm defined $$||x|| = \\sqrt{\\sum(x^2)}$$ Euclidean norm can interpreted length connection zero point specified vector. normalized vector, , computed : $$x' = x/||x||$$","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/normalize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalize a vector — normalize","text":"","code":"v <- rnorm(10) normalize(v) == v/sqrt(sum(v^2)) #>  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE"},{"path":"https://thieled.github.io/dictvectoR/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://thieled.github.io/dictvectoR/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/prepare_train_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Prepare text for fastText-model-training — prepare_train_data","title":"Prepare text for fastText-model-training — prepare_train_data","text":"Helper function prepare text training fastText model. (Caution: Tailored texts German language).","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/prepare_train_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prepare text for fastText-model-training — prepare_train_data","text":"","code":"prepare_train_data(df, text_field = \"text\", seed = 1)"},{"path":"https://thieled.github.io/dictvectoR/reference/prepare_train_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prepare text for fastText-model-training — prepare_train_data","text":"df data frame. text_field Name column df contains text cleaned. Default 'text'. seed Used random shuffling. Default 1.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/prepare_train_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prepare text for fastText-model-training — prepare_train_data","text":"character vector can directly used train fasttext model build_vectors.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/prepare_train_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prepare text for fastText-model-training — prepare_train_data","text":"Takes data.frame containing text. First checks length texts specified text_field using nsentence. Texts 3 sentences tokenized tokens sentences. texts passed clean_text fixed settings: tolower = T remove_punct = T replace_emojis = T replace_numbers = T remove_stopwords = F store_uncleaned = F count = T cleaned, short texts shuffled returned character vector.","code":""},{"path":[]},{"path":"https://thieled.github.io/dictvectoR/reference/prepare_train_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prepare text for fastText-model-training — prepare_train_data","text":"","code":"texts <- prepare_train_data(head(tw_data, 10), text_field = 'full_text')"},{"path":"https://thieled.github.io/dictvectoR/reference/remove_similar_words.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove too similar terms — remove_similar_words","title":"Remove too similar terms — remove_similar_words","text":"Removes similar terms data.frame word_df.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/remove_similar_words.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove too similar terms — remove_similar_words","text":"","code":"remove_similar_words(   word_df,   model,   word_field = \"words\",   compare_by = NULL,   compare_hits = T,   min_simil = 0.7,   win_threshold = 0.5 )"},{"path":"https://thieled.github.io/dictvectoR/reference/remove_similar_words.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove too similar terms — remove_similar_words","text":"word_df data.frame containing column words multi-word expressions. model fastText model, loaded load_model. word_field character. name column word_df contains words. compare_by character. Default NULL. name column compared. compare_hits logical. Default TRUE. true counts often one word 'beats' similar regard occurrences. min_simil Numerical (0-1). Default .7. Similarity threshold. Word pairs threshold considered dissimilar. win_threshold Numerical (0-1). Default .5. Determines threshold drop words, defined proportion won pairwise comparisons; resp., compare_by compare_hit set, mean proportional wins.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/remove_similar_words.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove too similar terms — remove_similar_words","text":"data.frame. Containing pairwise similarity table similar words.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/remove_similar_words.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Remove too similar terms — remove_similar_words","text":"Detects similar words multiword expressions word_df, using fastText model. cosine similarity threshold set min_simil. requested, similar words compared along variable specified compare_by, /number occurrences stored variable named hits. threshold dropping terms set win_threshold. indicates proportion many pairwise comparisons 'won' word question. compare_hits = T compare_by set, mean proportions. word 'wins' comparisions regarding frequency (wins_hits1 == 1), loses comparisions regaring set score ('wins_score1' == 0), value .5. Forces 'word_df' contain unique identifier called 'word_id'; re-uses first variable named 'id' unique identifier.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/remove_similar_words.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Remove too similar terms — remove_similar_words","text":"","code":"model <- fastrtext::load_model(system.file(\"extdata\",                                           \"tw_demo_model_sml.bin\",                                           package = \"dictvectoR\")) set.seed(1) word_df <- data.frame(words = c(\"unsere steuern\",                                \"steuerzahler\",                                \"unsere\",                                \"steuern\"),                      hits = c(2, 3, 15, 4),                      score = rnorm(4)) remove_similar_words(word_df,                     model,                     compare_by = \"score\",                     compare_hits = FALSE,                     win_threshold = .4) #>            words hits      score word_id #> 1 unsere steuern    2 -0.6264538       1 #> 2        steuern    4  1.5952808       4"},{"path":"https://thieled.github.io/dictvectoR/reference/repl_na.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace missing values. — repl_na","title":"Replace missing values. — repl_na","text":"Helper replace missing values. Default repalce NAs 'mean' - 1 'sd'.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/repl_na.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace missing values. — repl_na","text":"","code":"repl_na(x, replace_na = c(\"mean-sd\", \"min\", 0, F))"},{"path":"https://thieled.github.io/dictvectoR/reference/repl_na.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace missing values. — repl_na","text":"x numerical vector. replace_na Specifies value used replace NAs. Can take values: 'mean-sd' (charcter): replace NAs mean - 1sd. Default. 'min' (charcter): replace NAs minimum. 0 (numerical): replace NAs 0. FALSE (logical): replace NAs.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/repl_na.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Replace missing values. — repl_na","text":"","code":"a <- c(rnorm(7), NA, NA, NA) repl_na(a) == repl_na(a, 'mean-sd') #>  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE repl_na(a, 'min') #>  [1]  0.3295078 -0.8204684  0.4874291  0.7383247  0.5757814 -0.3053884 #>  [7]  1.5117812 -0.8204684 -0.8204684 -0.8204684 repl_na(a, 0) #>  [1]  0.3295078 -0.8204684  0.4874291  0.7383247  0.5757814 -0.3053884 #>  [7]  1.5117812  0.0000000  0.0000000  0.0000000 repl_na(a, FALSE) #>  [1]  0.3295078 -0.8204684  0.4874291  0.7383247  0.5757814 -0.3053884 #>  [7]  1.5117812         NA         NA         NA"},{"path":"https://thieled.github.io/dictvectoR/reference/simil_words2rep.html","id":null,"dir":"Reference","previous_headings":"","what":"Cosine similarity between words and a given vector. — simil_words2rep","title":"Cosine similarity between words and a given vector. — simil_words2rep","text":"Returns cosine similarity word data frame given vector representation.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/simil_words2rep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cosine similarity between words and a given vector. — simil_words2rep","text":"","code":"simil_words2rep(word_df, word_field = \"words\", rep, model)"},{"path":"https://thieled.github.io/dictvectoR/reference/simil_words2rep.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cosine similarity between words and a given vector. — simil_words2rep","text":"word_df data.frame containing column words multiword expressions. word_field character string indicating name column word_df contains words. rep given word-vector representation, stored numerical vector, matrix, sparse matrix object. length, resp. ncol rep must equal dimensions used fastText model. model fastText model, loaded fastrtext::load_model().","code":""},{"path":[]},{"path":"https://thieled.github.io/dictvectoR/reference/simil_words2rep.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cosine similarity between words and a given vector. — simil_words2rep","text":"","code":"model <- fastrtext::load_model(system.file(\"extdata\",                                \"tw_demo_model_sml.bin\",                                 package = \"dictvectoR\")) pop_rep <- tw_annot %>%            dplyr::filter(pop == 1) %>%            clean_text(text_field = \"full_text\") %>%            get_corpus_representation(model = model) words_df <- data.frame(words = c(\"coronadeutschland\", \"skandal\")) words_df$popsimil <- simil_words2rep(words_df,                                      word_field = \"words\",                                      rep = pop_rep,                                      model)"},{"path":"https://thieled.github.io/dictvectoR/reference/tw_annot.html","id":null,"dir":"Reference","previous_headings":"","what":"Annotated Tweets from German politicians. — tw_annot","title":"Annotated Tweets from German politicians. — tw_annot","text":"dataset containing 1,000 hand-coded Tweets, drawn [tw_data].","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/tw_annot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Annotated Tweets from German politicians. — tw_annot","text":"","code":"tw_annot"},{"path":"https://thieled.github.io/dictvectoR/reference/tw_annot.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Annotated Tweets from German politicians. — tw_annot","text":"data frame 20838 rows 8 variables: status_id Tweet ID ane Binary hand-coding anti-elitism ppc Binary hand-coding people-centrism pop Binary hand-coding populism. 1 either ane ppc 1 coder Coder identifier. B. AB Tweet parallel code. case, coding 1 least one coder decided code 1. user_id Twitter user ID twitter_handle Twitter handle party Political party followers_count number followers Aug 2022 created_at Date time Tweet created full_text Uncleaned Tweet rel_test Indicates Tweet parallel-coded reliability test ane_A Binary hand-coding anti-elitism coder ane_B Binary hand-coding anti-elitism coder B ppc_A Binary hand-coding people-centrism coder ppc_B Binary hand-coding people-centrism coder B","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/tw_annot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Annotated Tweets from German politicians. — tw_annot","text":"dataset contains 1,000 Tweets drawn stratified random sample population data [tw_data]. political party represented (least) 120 Tweets. populist parties AfD (250 Tweets) Die Linke (150 Tweets) oversampled, anticipated populist content parties. TWo expert coders, one author package, hand-coded Tweets along two binary categories populist communication: Anti-elitism people-centrism. coding followed instructions documented online supplementary files Thiele (2022). 90 Tweets parallel-coded reliability testing, resulting Krippendorff's Alphas .86 anti-elitism, .71 people-centrism, documented variables ane_A, ane_B, ppc_A, ppc_B.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/tw_annot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Annotated Tweets from German politicians. — tw_annot","text":"Thiele, D. (2022). Pandemic Populism? Covid-19 Triggered Populist Facebook User Comments Germany Austria. Politics Governance, 10(1), 185–196. https://doi.org/10.17645/pag.v10i1.4712","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/tw_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Tweets from German politicians. — tw_data","title":"Tweets from German politicians. — tw_data","text":"dataset containing 20,838 Tweets 32 German politicians, posted 2020-03-11 2021-09-25.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/tw_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tweets from German politicians. — tw_data","text":"","code":"tw_data"},{"path":"https://thieled.github.io/dictvectoR/reference/tw_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Tweets from German politicians. — tw_data","text":"data frame 20838 rows 8 variables: user_id Twitter user ID twitter_handle Twitter handle party Political party followers_count number followers Aug 2022 status_id Tweet ID created_at Date time Tweet created full_text Uncleaned text Tweet poppa_populism Mean populism score POPPA expert survey","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/tw_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Tweets from German politicians. — tw_data","text":"Twitter, EPINet Twitter Dataset, POPPA","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/tw_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tweets from German politicians. — tw_data","text":"Twitter accounts selected EPINetz Twitter Politicians Dataset 2021 (König et al., 2022). seven political parties represented German Parliament, five popular Twitter accounts politicians active federal level party representatives selected. accounts 30,000 followers selected. timeframe starts beginning Covid-19 pandemic ends one day German general elections 2021. account, maximum number (3,200) Tweets returned API v2 downloaded August 2022, using rtweet (Kearney, 2022). Quotes, re-tweets, Tweets outside timeframe excluded. Completeness dataset guaranteed. dataset also includes variable extracted POPPA Populism Political Parties Expert Survey, indicating mean expert rating populism per political party.","code":""},{"path":"https://thieled.github.io/dictvectoR/reference/tw_data.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tweets from German politicians. — tw_data","text":"Kearney, M. W., Sancho, L. R., Wickham, H., Heiss, ., Briatte, F., & Sidi, J. (2022). rtweet: Collecting Twitter Data. Retrieved https://CRAN.R-project.org/package=rtweet König, T., Schünemann, W. J., Brand, ., Freyberg, J., & Gertz, M. (2022). EPINetz Twitter Politicians Dataset 2021. New Resource Study German Twittersphere Application 2021 Federal Elections. Politische Vierteljahresschrift. https://doi.org/10.1007/s11615-022-00405-7 Meijers, M., & Zaslove, . (2020). Populism Political Parties Expert Survey 2018 (POPPA) (Data set). Harvard Dataverse. https://doi.org/10.7910/DVN/8NEL7B","code":""},{"path":"https://thieled.github.io/dictvectoR/news/index.html","id":"dictvector-0009000","dir":"Changelog","previous_headings":"","what":"dictvectoR 0.0.0.9000","title":"dictvectoR 0.0.0.9000","text":"Added NEWS.md file track changes package.","code":""}]
